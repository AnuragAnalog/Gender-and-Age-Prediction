{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gender and Age Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfoTfTYEY1Xn"
      },
      "source": [
        "# Gender and Age Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtLzwf_zY7MM"
      },
      "source": [
        "Dataset used was Kaggle's **AGE, GENDER AND ETHNICITY (FACE DATA) CSV** and can be found [here](https://www.kaggle.com/nipunarora8/age-gender-and-ethnicity-face-data-csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmi395lscPn6"
      },
      "source": [
        "# Required downloads\n",
        "\n",
        "!pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5RQp3V4Yq-O"
      },
      "source": [
        "# Required modules\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "from zipfile import ZipFile\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr2TEdx0bOzG"
      },
      "source": [
        "# Some configuration\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (12, 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w8GEppYbWFm"
      },
      "source": [
        "# Moving the credentials file to main dir\n",
        "\n",
        "!mkdir -p ~/.kaggle/\n",
        "!cp ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIF5Fe2ZxhlD",
        "outputId": "8d458133-33f0-497d-eab0-0294b2124221"
      },
      "source": [
        "# Download the dataset\n",
        "\n",
        "!kaggle datasets download -d nipunarora8/age-gender-and-ethnicity-face-data-csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading age-gender-and-ethnicity-face-data-csv.zip to /content\n",
            " 87% 55.0M/63.2M [00:01<00:00, 26.8MB/s]\n",
            "100% 63.2M/63.2M [00:01<00:00, 43.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZnQxn3mxlP-"
      },
      "source": [
        "# Extract the dataset\n",
        "\n",
        "with ZipFile('/content/age-gender-and-ethnicity-face-data-csv.zip', 'r') as zf:\n",
        "    zf.extractall('./')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tu__rs_-xxvq",
        "outputId": "8a97d457-e75f-49dc-cab0-393eb5cebdc3"
      },
      "source": [
        "# Loading the data\n",
        "\n",
        "data = pd.read_csv('age_gender.csv')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>gender</th>\n",
              "      <th>img_name</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161219203650636.jpg.chip.jpg</td>\n",
              "      <td>129 128 128 126 127 130 133 135 139 142 145 14...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161219222752047.jpg.chip.jpg</td>\n",
              "      <td>164 74 111 168 169 171 175 182 184 188 193 199...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161219222832191.jpg.chip.jpg</td>\n",
              "      <td>67 70 71 70 69 67 70 79 90 103 116 132 145 155...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161220144911423.jpg.chip.jpg</td>\n",
              "      <td>193 197 198 200 199 200 202 203 204 205 208 21...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161220144914327.jpg.chip.jpg</td>\n",
              "      <td>202 205 209 210 209 209 210 211 212 214 218 21...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  ...                                             pixels\n",
              "0    1  ...  129 128 128 126 127 130 133 135 139 142 145 14...\n",
              "1    1  ...  164 74 111 168 169 171 175 182 184 188 193 199...\n",
              "2    1  ...  67 70 71 70 69 67 70 79 90 103 116 132 145 155...\n",
              "3    1  ...  193 197 198 200 199 200 202 203 204 205 208 21...\n",
              "4    1  ...  202 205 209 210 209 209 210 211 212 214 218 21...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "ca_leVBox8FB",
        "outputId": "eb92d44e-1a00-4636-83ac-292815f10b1d"
      },
      "source": [
        "# Inspecting the data\n",
        "\n",
        "data.info()\n",
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23705 entries, 0 to 23704\n",
            "Data columns (total 5 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   age        23705 non-null  int64 \n",
            " 1   ethnicity  23705 non-null  int64 \n",
            " 2   gender     23705 non-null  int64 \n",
            " 3   img_name   23705 non-null  object\n",
            " 4   pixels     23705 non-null  object\n",
            "dtypes: int64(3), object(2)\n",
            "memory usage: 926.1+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>23705.000000</td>\n",
              "      <td>23705.000000</td>\n",
              "      <td>23705.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>33.300907</td>\n",
              "      <td>1.269226</td>\n",
              "      <td>0.477283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>19.885708</td>\n",
              "      <td>1.345638</td>\n",
              "      <td>0.499494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>45.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>116.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                age     ethnicity        gender\n",
              "count  23705.000000  23705.000000  23705.000000\n",
              "mean      33.300907      1.269226      0.477283\n",
              "std       19.885708      1.345638      0.499494\n",
              "min        1.000000      0.000000      0.000000\n",
              "25%       23.000000      0.000000      0.000000\n",
              "50%       29.000000      1.000000      0.000000\n",
              "75%       45.000000      2.000000      1.000000\n",
              "max      116.000000      4.000000      1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl_g9dQ0hXGB"
      },
      "source": [
        "# Change Image name\n",
        "\n",
        "data['img_name'] = data['img_name'].apply(lambda x: x.split('.')[0] + '.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNjcCfrV0DK8"
      },
      "source": [
        "# Important directory paths\n",
        "\n",
        "main_dir = './img_data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNN5zRz50Tcd"
      },
      "source": [
        "# Required functions\n",
        "\n",
        "def row2img(row, save_dir):\n",
        "    img_data = np.array(list(map(int, row['pixels'].split())), dtype='uint8').reshape(48, 48)\n",
        "\n",
        "    img = Image.fromarray(img_data)\n",
        "    img.save(save_dir+row['img_name'], format='jpeg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq4gKj47yT36"
      },
      "source": [
        "# Convert pixels to images\n",
        "\n",
        "if not os.path.isdir(main_dir):\n",
        "    os.mkdir(main_dir)\n",
        "\n",
        "_ = data.apply(lambda x: row2img(x, main_dir), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syOe1UetmJnY"
      },
      "source": [
        "# Actual Data\n",
        "\n",
        "actual_data = data[['age', 'gender', 'img_name']].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek29H6iejZpN",
        "outputId": "6961f92f-3a65-4c0d-ec96-3607f53c5cf9"
      },
      "source": [
        "# Getting the data\n",
        "\n",
        "img_h = 48\n",
        "img_w = 48\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1/255.,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_gen = datagen.flow_from_dataframe(\n",
        "    dataframe=actual_data,\n",
        "    directory=main_dir,\n",
        "    subset='training',\n",
        "    target_size=(img_h, img_w),\n",
        "    x_col='img_name',\n",
        "    y_col=['age', 'gender'],\n",
        "    class_mode=\"multi_output\"\n",
        ")\n",
        "\n",
        "test_gen = datagen.flow_from_dataframe(\n",
        "    dataframe=actual_data,\n",
        "    directory=main_dir,\n",
        "    subset='validation',\n",
        "    target_size=(img_h, img_w),\n",
        "    x_col='img_name',\n",
        "    y_col=['age', 'gender'],\n",
        "    class_mode=\"multi_output\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 18964 validated image filenames.\n",
            "Found 4741 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyIFhZsXksQZ",
        "outputId": "af2c6836-ef70-4efa-b98e-ccf2e630d9e8"
      },
      "source": [
        "# Getting the model\n",
        "\n",
        "input_layer = tf.keras.layers.Input(shape=(img_w, img_h, 3))\n",
        "\n",
        "pretrained = tf.keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_tensor=input_layer)\n",
        "\n",
        "for layer in pretrained.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "flatten = tf.keras.layers.Flatten()(pretrained.output)\n",
        "dense = tf.keras.layers.Dense(128, activation='relu')(flatten)\n",
        "dense = tf.keras.layers.Dense(64, activation='relu')(dense)\n",
        "dense = tf.keras.layers.Dense(2)(dense)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=pretrained.input, outputs=dense)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRjJoekUogLK",
        "outputId": "bf789286-99d0-4fb1-b623-0c8d18e28f1b"
      },
      "source": [
        "# Model Summary\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 48, 48, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 14,788,738\n",
            "Trainable params: 74,050\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXS0q9N6p6S8"
      },
      "source": [
        "# Model Hyperparameters\n",
        "\n",
        "epochs = 150\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGLrEOy3q1BU"
      },
      "source": [
        "# Compiling the model\n",
        "\n",
        "loss = ['mse']\n",
        "# metric = [tf.keras.metrics.Accuracy()]\n",
        "optim = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "model.compile(optimizer=optim, loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxB-z9i-pIrD"
      },
      "source": [
        "# Defining the callbacks\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5)\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('model_weights.hdf5', monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)\n",
        "\n",
        "callbacks = [model_checkpoint, reduce_lr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-9rzcjfrDtH",
        "outputId": "ed485387-d770-4082-bb85-f85404bffb65"
      },
      "source": [
        "# Fitting the model\n",
        "\n",
        "model.fit(train_gen, validation_data=test_gen, epochs=epochs, batch_size=batch_size, callbacks=callbacks, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "593/593 [==============================] - 50s 33ms/step - loss: 1089.2958 - val_loss: 695.5153\n",
            "Epoch 2/150\n",
            "593/593 [==============================] - 19s 31ms/step - loss: 309.2031 - val_loss: 500.6018\n",
            "Epoch 3/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 273.8837 - val_loss: 431.7673\n",
            "Epoch 4/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 254.9098 - val_loss: 437.0286\n",
            "Epoch 5/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 242.6706 - val_loss: 462.4454\n",
            "Epoch 6/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 236.0955 - val_loss: 394.4914\n",
            "Epoch 7/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 244.5144 - val_loss: 393.3239\n",
            "Epoch 8/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 232.8604 - val_loss: 438.5179\n",
            "Epoch 9/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 229.7594 - val_loss: 385.0585\n",
            "Epoch 10/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 223.3398 - val_loss: 410.5375\n",
            "Epoch 11/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 226.1494 - val_loss: 416.1435\n",
            "Epoch 12/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 229.3889 - val_loss: 390.6815\n",
            "Epoch 13/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 227.4790 - val_loss: 380.9806\n",
            "Epoch 14/150\n",
            "593/593 [==============================] - 19s 31ms/step - loss: 221.2966 - val_loss: 346.3559\n",
            "Epoch 15/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 215.1960 - val_loss: 340.2964\n",
            "Epoch 16/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 218.1171 - val_loss: 364.4060\n",
            "Epoch 17/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 216.2373 - val_loss: 344.0271\n",
            "Epoch 18/150\n",
            "593/593 [==============================] - 19s 31ms/step - loss: 220.8857 - val_loss: 381.3274\n",
            "Epoch 19/150\n",
            "593/593 [==============================] - 19s 31ms/step - loss: 213.3839 - val_loss: 350.6565\n",
            "Epoch 20/150\n",
            "593/593 [==============================] - 19s 31ms/step - loss: 209.3527 - val_loss: 326.1945\n",
            "Epoch 21/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 211.1763 - val_loss: 369.1805\n",
            "Epoch 22/150\n",
            "593/593 [==============================] - 19s 31ms/step - loss: 211.5663 - val_loss: 388.5951\n",
            "Epoch 23/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 212.4692 - val_loss: 357.3895\n",
            "Epoch 24/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 202.6356 - val_loss: 364.2977\n",
            "Epoch 25/150\n",
            "593/593 [==============================] - 19s 31ms/step - loss: 208.9365 - val_loss: 336.7523\n",
            "Epoch 26/150\n",
            "593/593 [==============================] - 19s 31ms/step - loss: 205.9955 - val_loss: 362.5113\n",
            "Epoch 27/150\n",
            "593/593 [==============================] - 19s 31ms/step - loss: 204.3257 - val_loss: 360.4256\n",
            "Epoch 28/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 207.6944 - val_loss: 352.5843\n",
            "Epoch 29/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 203.2252 - val_loss: 350.6964\n",
            "Epoch 30/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 204.0597 - val_loss: 345.7385\n",
            "Epoch 31/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 204.7974 - val_loss: 347.7164\n",
            "Epoch 32/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 203.3841 - val_loss: 350.2569\n",
            "Epoch 33/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 200.5531 - val_loss: 345.3053\n",
            "Epoch 34/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 207.1752 - val_loss: 339.6259\n",
            "Epoch 35/150\n",
            "593/593 [==============================] - 19s 31ms/step - loss: 207.7694 - val_loss: 351.4446\n",
            "Epoch 36/150\n",
            "593/593 [==============================] - 19s 31ms/step - loss: 203.7134 - val_loss: 341.3190\n",
            "Epoch 37/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 203.4630 - val_loss: 340.4245\n",
            "Epoch 38/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 202.2570 - val_loss: 336.0198\n",
            "Epoch 39/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 208.5407 - val_loss: 341.4454\n",
            "Epoch 40/150\n",
            "593/593 [==============================] - 19s 31ms/step - loss: 208.8630 - val_loss: 334.7328\n",
            "Epoch 41/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 202.1617 - val_loss: 338.9933\n",
            "Epoch 42/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 205.2158 - val_loss: 343.1340\n",
            "Epoch 43/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 199.8693 - val_loss: 341.8705\n",
            "Epoch 44/150\n",
            "593/593 [==============================] - 19s 31ms/step - loss: 203.0410 - val_loss: 340.2373\n",
            "Epoch 45/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 202.1145 - val_loss: 340.8733\n",
            "Epoch 46/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 201.3610 - val_loss: 339.1465\n",
            "Epoch 47/150\n",
            "593/593 [==============================] - 19s 31ms/step - loss: 204.4423 - val_loss: 343.9258\n",
            "Epoch 48/150\n",
            "593/593 [==============================] - 19s 31ms/step - loss: 202.7760 - val_loss: 341.4597\n",
            "Epoch 49/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 204.2854 - val_loss: 343.6229\n",
            "Epoch 50/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 201.8264 - val_loss: 342.7371\n",
            "Epoch 51/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 206.1697 - val_loss: 341.4761\n",
            "Epoch 52/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 203.7473 - val_loss: 345.8239\n",
            "Epoch 53/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 206.5982 - val_loss: 340.0869\n",
            "Epoch 54/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 208.4995 - val_loss: 339.1060\n",
            "Epoch 55/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 204.4733 - val_loss: 343.6076\n",
            "Epoch 56/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 201.7277 - val_loss: 339.9405\n",
            "Epoch 57/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 209.8436 - val_loss: 343.4738\n",
            "Epoch 58/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 207.9211 - val_loss: 342.5468\n",
            "Epoch 59/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 205.1181 - val_loss: 343.4437\n",
            "Epoch 60/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 205.2186 - val_loss: 340.6198\n",
            "Epoch 61/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 205.3971 - val_loss: 339.7291\n",
            "Epoch 62/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 206.0302 - val_loss: 340.0691\n",
            "Epoch 63/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 201.0736 - val_loss: 344.0728\n",
            "Epoch 64/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 204.3952 - val_loss: 344.4901\n",
            "Epoch 65/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 208.8307 - val_loss: 342.5670\n",
            "Epoch 66/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 204.1263 - val_loss: 345.1395\n",
            "Epoch 67/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 209.5225 - val_loss: 341.9241\n",
            "Epoch 68/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 202.6100 - val_loss: 340.0787\n",
            "Epoch 69/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 199.0189 - val_loss: 336.4887\n",
            "Epoch 70/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 205.1349 - val_loss: 336.5956\n",
            "Epoch 71/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 205.6052 - val_loss: 341.6917\n",
            "Epoch 72/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 205.0148 - val_loss: 341.0602\n",
            "Epoch 73/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 203.0690 - val_loss: 338.7333\n",
            "Epoch 74/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 199.0597 - val_loss: 344.3193\n",
            "Epoch 75/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 201.5188 - val_loss: 340.3862\n",
            "Epoch 76/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 203.6124 - val_loss: 340.8975\n",
            "Epoch 77/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 208.6172 - val_loss: 341.0138\n",
            "Epoch 78/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 202.3871 - val_loss: 338.3983\n",
            "Epoch 79/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 205.0571 - val_loss: 342.4760\n",
            "Epoch 80/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 205.1648 - val_loss: 337.7874\n",
            "Epoch 81/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 199.1096 - val_loss: 342.3484\n",
            "Epoch 82/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 205.6653 - val_loss: 338.9241\n",
            "Epoch 83/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 204.3112 - val_loss: 341.2065\n",
            "Epoch 84/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 204.1972 - val_loss: 337.3616\n",
            "Epoch 85/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 206.2170 - val_loss: 337.3595\n",
            "Epoch 86/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 202.7859 - val_loss: 338.5260\n",
            "Epoch 87/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 205.0050 - val_loss: 341.1153\n",
            "Epoch 88/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 203.1883 - val_loss: 339.7241\n",
            "Epoch 89/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 205.0920 - val_loss: 340.8021\n",
            "Epoch 90/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 204.8710 - val_loss: 341.4196\n",
            "Epoch 91/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 196.7729 - val_loss: 342.6798\n",
            "Epoch 92/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 202.8939 - val_loss: 338.0394\n",
            "Epoch 93/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 201.6193 - val_loss: 341.7267\n",
            "Epoch 94/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 204.5257 - val_loss: 342.2148\n",
            "Epoch 95/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 198.3930 - val_loss: 337.0144\n",
            "Epoch 96/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 208.3380 - val_loss: 342.4492\n",
            "Epoch 97/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 204.8626 - val_loss: 336.9678\n",
            "Epoch 98/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 206.8405 - val_loss: 334.1432\n",
            "Epoch 99/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 201.9942 - val_loss: 336.1066\n",
            "Epoch 100/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 208.1836 - val_loss: 346.6953\n",
            "Epoch 101/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 199.9905 - val_loss: 341.0631\n",
            "Epoch 102/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 208.4309 - val_loss: 344.5331\n",
            "Epoch 103/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 203.6922 - val_loss: 343.0471\n",
            "Epoch 104/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 204.0360 - val_loss: 344.9756\n",
            "Epoch 105/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 205.7720 - val_loss: 342.3027\n",
            "Epoch 106/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 207.4399 - val_loss: 340.7479\n",
            "Epoch 107/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 205.4291 - val_loss: 341.7100\n",
            "Epoch 108/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 206.7837 - val_loss: 345.1777\n",
            "Epoch 109/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 202.4440 - val_loss: 338.8795\n",
            "Epoch 110/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 205.6381 - val_loss: 341.3868\n",
            "Epoch 111/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 203.0647 - val_loss: 336.4673\n",
            "Epoch 112/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 208.4308 - val_loss: 339.5292\n",
            "Epoch 113/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 202.4034 - val_loss: 340.0698\n",
            "Epoch 114/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 209.7490 - val_loss: 344.3167\n",
            "Epoch 115/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 199.8907 - val_loss: 337.2855\n",
            "Epoch 116/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 203.3468 - val_loss: 339.5269\n",
            "Epoch 117/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 202.7517 - val_loss: 337.4557\n",
            "Epoch 118/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 206.2725 - val_loss: 337.1054\n",
            "Epoch 119/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 206.0598 - val_loss: 342.1210\n",
            "Epoch 120/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 205.4333 - val_loss: 339.9059\n",
            "Epoch 121/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 205.1648 - val_loss: 335.5311\n",
            "Epoch 122/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 201.0379 - val_loss: 342.2538\n",
            "Epoch 123/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 206.3367 - val_loss: 341.2648\n",
            "Epoch 124/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 209.7142 - val_loss: 341.5697\n",
            "Epoch 125/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 200.5236 - val_loss: 339.6737\n",
            "Epoch 126/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 203.9837 - val_loss: 342.9050\n",
            "Epoch 127/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 201.3085 - val_loss: 340.8111\n",
            "Epoch 128/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 207.7948 - val_loss: 341.8429\n",
            "Epoch 129/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 204.1778 - val_loss: 341.3694\n",
            "Epoch 130/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 207.3066 - val_loss: 342.0707\n",
            "Epoch 131/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 206.8016 - val_loss: 337.8896\n",
            "Epoch 132/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 204.4587 - val_loss: 342.5001\n",
            "Epoch 133/150\n",
            "593/593 [==============================] - 19s 33ms/step - loss: 200.1180 - val_loss: 340.3869\n",
            "Epoch 134/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 200.7796 - val_loss: 339.7776\n",
            "Epoch 135/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 207.0030 - val_loss: 342.3652\n",
            "Epoch 136/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 198.7480 - val_loss: 340.5114\n",
            "Epoch 137/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 203.2834 - val_loss: 343.6684\n",
            "Epoch 138/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 207.0901 - val_loss: 343.1811\n",
            "Epoch 139/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 203.5994 - val_loss: 342.2417\n",
            "Epoch 140/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 203.6799 - val_loss: 341.0522\n",
            "Epoch 141/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 203.8137 - val_loss: 341.9513\n",
            "Epoch 142/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 201.8205 - val_loss: 341.2711\n",
            "Epoch 143/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 202.7892 - val_loss: 339.3116\n",
            "Epoch 144/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 205.8477 - val_loss: 343.9620\n",
            "Epoch 145/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 201.8066 - val_loss: 339.6883\n",
            "Epoch 146/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 206.6060 - val_loss: 339.1302\n",
            "Epoch 147/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 206.4785 - val_loss: 342.4074\n",
            "Epoch 148/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 202.9644 - val_loss: 339.2976\n",
            "Epoch 149/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 206.6578 - val_loss: 340.0172\n",
            "Epoch 150/150\n",
            "593/593 [==============================] - 19s 32ms/step - loss: 201.0671 - val_loss: 339.3905\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff1d03c6150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}